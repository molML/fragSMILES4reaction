epoch,step,train_loss,val_loss
0,440,1.7251430749893188,1.3196544647216797
1,881,1.2683851718902588,1.1149060726165771
2,1322,1.124329686164856,1.0219142436981201
3,1763,1.0292794704437256,0.9286462068557739
4,2204,0.9420852661132812,0.8370694518089294
5,2645,0.8494442701339722,0.7757413387298584
6,3086,0.770240306854248,0.7287942171096802
7,3527,0.7069699764251709,0.6848185062408447
8,3968,0.6558083891868591,0.6814817190170288
9,4409,0.6162984371185303,0.6644471883773804
10,4850,0.584064781665802,0.6707289218902588
11,5291,0.5536879897117615,0.675137460231781
12,5732,0.5287990570068359,0.656785786151886
13,6173,0.5060798525810242,0.6843777894973755
14,6614,0.48661330342292786,0.6752201914787292
15,7055,0.4692937135696411,0.6748663187026978
16,7496,0.45220947265625,0.6899885535240173
17,7937,0.43819862604141235,0.6790573596954346
18,8378,0.42580145597457886,0.7081590294837952
19,8819,0.41296130418777466,0.7254565358161926
20,9260,0.40130603313446045,0.7130039930343628
21,9701,0.39200466871261597,0.7226674556732178
22,10142,0.3827533423900604,0.7056835889816284
23,10583,0.37388405203819275,0.7308478951454163
