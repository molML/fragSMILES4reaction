epoch,step,train_loss,val_loss
0,440,1.9632599353790283,1.4606691598892212
1,881,1.4526970386505127,1.245452880859375
2,1322,1.3036137819290161,1.1340522766113281
3,1763,1.2145668268203735,1.0552691221237183
4,2204,1.1523141860961914,0.99430251121521
5,2645,1.0976569652557373,0.9340749979019165
6,3086,1.0473318099975586,0.8811492919921875
7,3527,0.9997976422309875,0.8326596617698669
8,3968,0.9531400799751282,0.8022090196609497
9,4409,0.9096308946609497,0.7598294019699097
10,4850,0.8722687363624573,0.7404133677482605
11,5291,0.8353763818740845,0.711629331111908
12,5732,0.8035448789596558,0.6986778378486633
13,6173,0.7750457525253296,0.6833575367927551
14,6614,0.7497569918632507,0.6643975973129272
15,7055,0.7285362482070923,0.6507263779640198
16,7496,0.7083588242530823,0.6401923894882202
17,7937,0.6912556886672974,0.6217376589775085
18,8378,0.6767431497573853,0.6210616230964661
19,8819,0.6620931625366211,0.6059741973876953
20,9260,0.6476401686668396,0.5940494537353516
21,9701,0.6363688111305237,0.5895588994026184
22,10142,0.6254481673240662,0.5733590722084045
23,10583,0.6155035495758057,0.5636672973632812
