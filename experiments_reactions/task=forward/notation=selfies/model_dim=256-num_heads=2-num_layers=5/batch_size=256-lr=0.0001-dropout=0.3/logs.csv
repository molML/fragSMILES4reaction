epoch,step,train_loss,val_loss
0,881,1.695556640625,1.2385847568511963
1,1763,1.2425601482391357,1.0548280477523804
2,2645,1.1031607389450073,0.9515545964241028
3,3527,1.0134944915771484,0.8814511895179749
4,4409,0.9372332692146301,0.7827097177505493
5,5291,0.8563054203987122,0.7168543338775635
6,6173,0.7793757319450378,0.6636703014373779
7,7055,0.7163683772087097,0.6224279999732971
8,7937,0.6648967862129211,0.5934446454048157
9,8819,0.623294472694397,0.5681625008583069
10,9701,0.58831787109375,0.5430077314376831
11,10583,0.5561484694480896,0.5373443365097046
12,11465,0.5300909280776978,0.5140479803085327
13,12347,0.5070446729660034,0.5002732872962952
14,13229,0.4871775805950165,0.49946093559265137
15,14111,0.4699595272541046,0.47780272364616394
16,14993,0.4529416859149933,0.49918505549430847
17,15875,0.4389761984348297,0.48107457160949707
18,16757,0.42653152346611023,0.46889981627464294
19,17639,0.4138628840446472,0.4640381336212158
20,18521,0.4023585617542267,0.4512069821357727
21,19403,0.3928738534450531,0.45154905319213867
22,20285,0.3835328221321106,0.4369103014469147
