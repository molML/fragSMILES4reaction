epoch,step,train_loss,val_loss
0,881,2.5769641399383545,1.6071269512176514
1,1763,1.5772606134414673,1.2659525871276855
2,2645,1.3422807455062866,1.058732032775879
3,3527,1.1855261325836182,0.9258106350898743
4,4409,1.072551965713501,0.8280330896377563
5,5291,0.9882068037986755,0.7616753578186035
6,6173,0.9258463382720947,0.7120554447174072
7,7055,0.8742650747299194,0.6696577668190002
8,7937,0.8345892429351807,0.6335482597351074
9,8819,0.7995964288711548,0.6051048636436462
10,9701,0.7731404900550842,0.5835035443305969
11,10583,0.7465622425079346,0.5662434697151184
12,11465,0.7239856719970703,0.5423108339309692
13,12347,0.704653799533844,0.5279089212417603
14,13229,0.6864443421363831,0.5135579705238342
15,14111,0.6703037619590759,0.4970400929450989
16,14993,0.655340313911438,0.48768898844718933
17,15875,0.6410800218582153,0.47642838954925537
18,16757,0.630050539970398,0.4665093719959259
19,17639,0.6167800426483154,0.45910900831222534
20,18521,0.6059044003486633,0.44703400135040283
21,19403,0.5966030955314636,0.439426451921463
