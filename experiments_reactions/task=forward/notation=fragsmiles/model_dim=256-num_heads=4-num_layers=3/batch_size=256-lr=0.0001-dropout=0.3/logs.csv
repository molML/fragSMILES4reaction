epoch,step,train_loss,val_loss
0,881,2.5376012325286865,1.5575313568115234
1,1763,1.5134557485580444,1.2295013666152954
2,2645,1.279191255569458,1.0180243253707886
3,3527,1.1160398721694946,0.8634430766105652
4,4409,0.9929221272468567,0.7630594968795776
5,5291,0.902056872844696,0.6946375966072083
6,6173,0.8354251980781555,0.6394392848014832
7,7055,0.7801598906517029,0.5903297662734985
8,7937,0.7343632578849792,0.555141806602478
9,8819,0.6957473158836365,0.5247958898544312
10,9701,0.6650739908218384,0.5008136630058289
11,10583,0.6349519491195679,0.4797687828540802
12,11465,0.6105431914329529,0.4574941396713257
13,12347,0.5883784294128418,0.4458225667476654
14,13229,0.568449854850769,0.4270758330821991
15,14111,0.5497397184371948,0.4180808365345001
16,14993,0.5341722965240479,0.4042500853538513
17,15875,0.5186692476272583,0.3914276361465454
18,16757,0.5065548419952393,0.3875235617160797
19,17639,0.4929800033569336,0.37755146622657776
20,18521,0.4808751344680786,0.370956152677536
21,19403,0.47121286392211914,0.3627889156341553
22,20285,0.46118995547294617,0.35440903902053833
