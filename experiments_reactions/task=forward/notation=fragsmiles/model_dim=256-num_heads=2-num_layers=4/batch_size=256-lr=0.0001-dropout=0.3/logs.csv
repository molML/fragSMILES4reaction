epoch,step,train_loss,val_loss
0,881,2.522056818008423,1.5859471559524536
1,1763,1.5146759748458862,1.2633236646652222
2,2645,1.2729154825210571,1.0200278759002686
3,3527,1.099644660949707,0.8508467078208923
4,4409,0.9721278548240662,0.7506923675537109
5,5291,0.8771888613700867,0.6695387363433838
6,6173,0.8075013756752014,0.6173825860023499
7,7055,0.7494438886642456,0.572280764579773
8,7937,0.702269971370697,0.5313262939453125
9,8819,0.6616739630699158,0.4991908073425293
10,9701,0.6289588809013367,0.4764881730079651
11,10583,0.5978900790214539,0.4543081820011139
12,11465,0.5718829035758972,0.43107667565345764
13,12347,0.5487714409828186,0.4212263226509094
14,13229,0.5287961363792419,0.40548089146614075
15,14111,0.5087500214576721,0.38449826836586
16,14993,0.4927958548069,0.37518811225891113
17,15875,0.477606862783432,0.3665527105331421
18,16757,0.465343177318573,0.3591747581958771
19,17639,0.4519294798374176,0.35308825969696045
20,18521,0.44012826681137085,0.34358373284339905
21,19403,0.4306432008743286,0.33880817890167236
22,20285,0.42214828729629517,0.33317047357559204
