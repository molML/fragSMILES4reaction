epoch,step,train_loss,val_loss
0,881,2.607300043106079,1.6060726642608643
1,1763,1.607581615447998,1.273371934890747
2,2645,1.3719123601913452,1.0776628255844116
3,3527,1.2270702123641968,0.9570615887641907
4,4409,1.1279207468032837,0.8729530572891235
5,5291,1.052220344543457,0.8112295866012573
6,6173,0.9955432415008545,0.7648304104804993
7,7055,0.9475410580635071,0.7229177951812744
8,7937,0.9098465442657471,0.6883009076118469
9,8819,0.8767030239105225,0.6671366691589355
10,9701,0.8517109751701355,0.6351206302642822
11,10583,0.8271001577377319,0.6191236972808838
12,11465,0.8056266903877258,0.599412739276886
13,12347,0.7876220345497131,0.5849266648292542
14,13229,0.7704150676727295,0.5738434791564941
15,14111,0.7543567419052124,0.5568768978118896
16,14993,0.7410802841186523,0.5487822890281677
17,15875,0.7277024984359741,0.537606418132782
18,16757,0.7179930210113525,0.5249343514442444
19,17639,0.7062777280807495,0.5224251747131348
20,18521,0.6952342987060547,0.5114474892616272
21,19403,0.6879681944847107,0.5047983527183533
