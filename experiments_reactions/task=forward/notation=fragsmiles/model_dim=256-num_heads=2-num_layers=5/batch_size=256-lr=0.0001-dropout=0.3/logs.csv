epoch,step,train_loss,val_loss
0,881,2.5427072048187256,1.5991886854171753
1,1763,1.521471619606018,1.297343373298645
2,2645,1.2984470129013062,1.0962779521942139
3,3527,1.1328569650650024,0.8937345147132874
4,4409,0.9879356622695923,0.7649883031845093
5,5291,0.8793092966079712,0.6758418679237366
6,6173,0.8012372255325317,0.6203743815422058
7,7055,0.7394881248474121,0.5664750337600708
8,7937,0.689872145652771,0.5240758061408997
9,8819,0.6470668911933899,0.4940250515937805
10,9701,0.6118766665458679,0.4658355712890625
11,10583,0.5782671570777893,0.4392246901988983
12,11465,0.549953818321228,0.4176087975502014
13,12347,0.5248990058898926,0.3968967795372009
14,13229,0.5027785301208496,0.3836129605770111
15,14111,0.4815191924571991,0.36613407731056213
16,14993,0.4638526141643524,0.35595399141311646
17,15875,0.44822683930397034,0.34449630975723267
18,16757,0.4346609115600586,0.3361157774925232
19,17639,0.42066916823387146,0.3298990726470947
20,18521,0.40834173560142517,0.322546124458313
21,19403,0.397585928440094,0.3169349730014801
22,20285,0.3887115716934204,0.3094829320907593
23,21167,0.38016122579574585,0.30300113558769226
