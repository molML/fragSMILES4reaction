epoch,step,train_loss,val_loss
0,881,2.5224475860595703,1.5821484327316284
1,1763,1.5113680362701416,1.2778154611587524
2,2645,1.2940795421600342,1.0927724838256836
3,3527,1.1416486501693726,0.912527322769165
4,4409,1.0083913803100586,0.7865077257156372
5,5291,0.9016349911689758,0.693749189376831
6,6173,0.8233522176742554,0.6369966268539429
7,7055,0.7632418870925903,0.5833145976066589
8,7937,0.7143458127975464,0.542138934135437
9,8819,0.6719743609428406,0.5185642838478088
10,9701,0.6372448205947876,0.48523539304733276
11,10583,0.603907585144043,0.4580089747905731
12,11465,0.5745933651924133,0.4375048279762268
13,12347,0.5491359233856201,0.4163878560066223
14,13229,0.5262596011161804,0.3990733027458191
15,14111,0.5041369199752808,0.3828331232070923
16,14993,0.48563599586486816,0.37338772416114807
17,15875,0.4687868356704712,0.36029234528541565
18,16757,0.45587053894996643,0.35186728835105896
19,17639,0.4409557580947876,0.3448435664176941
20,18521,0.4276488423347473,0.3385205864906311
21,19403,0.4172717034816742,0.3291758596897125
22,20285,0.4071923792362213,0.3202860951423645
23,21167,0.3977910280227661,0.31496813893318176
