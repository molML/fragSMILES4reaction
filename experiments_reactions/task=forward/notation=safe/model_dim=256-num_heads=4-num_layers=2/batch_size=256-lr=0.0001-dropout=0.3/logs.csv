epoch,step,train_loss,val_loss
0,881,1.7863695621490479,1.2569844722747803
1,1763,1.2871227264404297,1.0671535730361938
2,2645,1.1524115800857544,0.9553790092468262
3,3527,1.062837839126587,0.8481692671775818
4,4409,0.9936681985855103,0.7856028079986572
5,5291,0.9406359791755676,0.7279528975486755
6,6173,0.8959436416625977,0.6843613982200623
7,7055,0.860253095626831,0.6654137969017029
8,7937,0.8282155394554138,0.6227865815162659
9,8819,0.8020758628845215,0.6104673743247986
10,9701,0.7786799669265747,0.5820554494857788
11,10583,0.7568303942680359,0.5674435496330261
12,11465,0.7380456328392029,0.5467314720153809
13,12347,0.7208297848701477,0.5409833192825317
14,13229,0.7055365443229675,0.5212173461914062
15,14111,0.6912965774536133,0.5115914940834045
16,14993,0.6771335005760193,0.4990895986557007
17,15875,0.6661729216575623,0.4884585440158844
18,16757,0.654962956905365,0.4790187180042267
19,17639,0.6438248157501221,0.4735426604747772
20,18521,0.633226752281189,0.46460723876953125
21,19403,0.6251576542854309,0.4580766260623932
