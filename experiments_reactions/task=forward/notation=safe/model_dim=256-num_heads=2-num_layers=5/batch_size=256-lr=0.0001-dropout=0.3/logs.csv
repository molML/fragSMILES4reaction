epoch,step,train_loss,val_loss
0,881,1.7085611820220947,1.1899385452270508
1,1763,1.1866745948791504,1.004868507385254
2,2645,1.0476025342941284,0.9067959785461426
3,3527,0.955512285232544,0.8396143913269043
4,4409,0.8780983686447144,0.7523343563079834
5,5291,0.8158631920814514,0.7085825204849243
6,6173,0.7621810436248779,0.6470881700515747
7,7055,0.7185851335525513,0.6172715425491333
8,7937,0.6793704032897949,0.5804294943809509
9,8819,0.6464395523071289,0.5487809181213379
10,9701,0.6163280606269836,0.5029988288879395
11,10583,0.5884451866149902,0.4913107454776764
12,11465,0.5643562078475952,0.4739498198032379
13,12347,0.5410724878311157,0.46677708625793457
14,13229,0.521740198135376,0.42951521277427673
15,14111,0.503525972366333,0.4170666038990021
16,14993,0.4860905408859253,0.40733596682548523
17,15875,0.47169262170791626,0.39765018224716187
18,16757,0.4577138423919678,0.38920149207115173
19,17639,0.44446465373039246,0.36328256130218506
20,18521,0.43165066838264465,0.36206740140914917
21,19403,0.4216655492782593,0.3500650227069855
22,20285,0.41099560260772705,0.34141120314598083
23,21167,0.40182358026504517,0.3422195315361023
