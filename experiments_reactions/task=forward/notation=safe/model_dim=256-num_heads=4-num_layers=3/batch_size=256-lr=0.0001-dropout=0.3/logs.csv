epoch,step,train_loss,val_loss
0,881,1.7415614128112793,1.2222332954406738
1,1763,1.2253506183624268,1.0142903327941895
2,2645,1.0836650133132935,0.898945152759552
3,3527,0.9853399395942688,0.798517644405365
4,4409,0.9099938273429871,0.7436513304710388
5,5291,0.8514630198478699,0.6869426369667053
6,6173,0.8025891780853271,0.6313862800598145
7,7055,0.7627127766609192,0.6092200875282288
8,7937,0.7260609269142151,0.5751410126686096
9,8819,0.6951159238815308,0.5440679788589478
10,9701,0.6679195165634155,0.526369571685791
11,10583,0.6428912281990051,0.5077788829803467
12,11465,0.6219171285629272,0.4898390769958496
13,12347,0.6020394563674927,0.4798840880393982
14,13229,0.5852925777435303,0.4559744894504547
15,14111,0.5696856379508972,0.4397178590297699
16,14993,0.554263174533844,0.43208736181259155
17,15875,0.5421860814094543,0.41807034611701965
18,16757,0.5301461815834045,0.401315838098526
19,17639,0.5182160139083862,0.3996555507183075
20,18521,0.5066609382629395,0.3915088474750519
21,19403,0.4977039098739624,0.38142648339271545
22,20285,0.48867660760879517,0.368164986371994
