epoch,step,train_loss,val_loss
0,440,2.0444416999816895,1.380028247833252
1,881,1.3973866701126099,1.1782597303390503
2,1322,1.240570068359375,1.0695282220840454
3,1763,1.1470763683319092,0.9875312447547913
4,2204,1.0741838216781616,0.9177009463310242
5,2645,1.014269232749939,0.852484405040741
6,3086,0.9616835713386536,0.7984470725059509
7,3527,0.9176947474479675,0.7552009224891663
8,3968,0.877682089805603,0.7122979760169983
9,4409,0.8438664674758911,0.6800068616867065
10,4850,0.8138234615325928,0.6466348171234131
11,5291,0.78536456823349,0.6181623935699463
12,5732,0.7601971626281738,0.5976448059082031
13,6173,0.7361816763877869,0.5805806517601013
14,6614,0.7155134677886963,0.557149350643158
15,7055,0.6958094835281372,0.5436344742774963
16,7496,0.677070140838623,0.5366196036338806
17,7937,0.6614128947257996,0.5192212462425232
18,8378,0.6462950706481934,0.49967172741889954
19,8819,0.6312379240989685,0.49253809452056885
20,9260,0.617008626461029,0.48856014013290405
21,9701,0.605780303478241,0.47102004289627075
22,10142,0.5940546989440918,0.465320885181427
23,10583,0.5836994051933289,0.46317702531814575
24,11024,0.5732041597366333,0.44510725140571594
25,11465,0.562441885471344,0.43816354870796204
26,11906,0.5539356470108032,0.4299241602420807
