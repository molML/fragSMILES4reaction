epoch,step,train_loss,val_loss
0,440,1.7388172149658203,1.265789270401001
1,881,1.2008599042892456,1.032981276512146
2,1322,1.048343539237976,0.8978639245033264
3,1763,0.9464327096939087,0.7862287759780884
4,2204,0.8634507060050964,0.7214564085006714
5,2645,0.795753538608551,0.649410605430603
6,3086,0.7390555739402771,0.6102034449577332
7,3527,0.692803144454956,0.5629255771636963
8,3968,0.6516856551170349,0.5484439134597778
9,4409,0.618219792842865,0.5222049355506897
10,4850,0.5886334180831909,0.4855126142501831
11,5291,0.5622572898864746,0.47292807698249817
12,5732,0.539717435836792,0.44392961263656616
13,6173,0.5195090174674988,0.43911483883857727
14,6614,0.502078115940094,0.42479774355888367
15,7055,0.48625463247299194,0.40326622128486633
16,7496,0.4712764620780945,0.39684486389160156
17,7937,0.45847228169441223,0.3762269616127014
18,8378,0.4466392397880554,0.36787962913513184
19,8819,0.434603750705719,0.3612002730369568
20,9260,0.4232444763183594,0.3549079895019531
21,9701,0.41429731249809265,0.3443824350833893
22,10142,0.40531232953071594,0.3348754346370697
