epoch,step,train_loss,val_loss
0,881,1.7109546661376953,1.1906318664550781
1,1763,1.1969045400619507,0.9932144284248352
2,2645,1.0549355745315552,0.8860943913459778
3,3527,0.9628965854644775,0.7992603182792664
4,4409,0.8869349360466003,0.7290689945220947
5,5291,0.8259543180465698,0.674165666103363
6,6173,0.7730470895767212,0.6180922985076904
7,7055,0.7296120524406433,0.5854284167289734
8,7937,0.6915122866630554,0.5475739240646362
9,8819,0.6593812108039856,0.538921594619751
10,9701,0.6305481195449829,0.4963029623031616
11,10583,0.6034906506538391,0.4815153181552887
12,11465,0.5800678730010986,0.46345996856689453
13,12347,0.5582794547080994,0.4471399784088135
14,13229,0.5390062928199768,0.4105284512042999
15,14111,0.5212444067001343,0.4136340022087097
16,14993,0.5044323801994324,0.3943548798561096
17,15875,0.4901004135608673,0.38553571701049805
18,16757,0.4766727387905121,0.37199345231056213
19,17639,0.46353578567504883,0.36409977078437805
20,18521,0.45092883706092834,0.35467007756233215
21,19403,0.44106897711753845,0.34214672446250916
22,20285,0.4305325746536255,0.3381868898868561
23,21167,0.42162883281707764,0.32465386390686035
