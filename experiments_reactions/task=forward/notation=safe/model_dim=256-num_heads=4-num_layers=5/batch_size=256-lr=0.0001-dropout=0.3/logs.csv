epoch,step,train_loss,val_loss
0,881,1.6999160051345825,1.161414384841919
1,1763,1.1693018674850464,0.9739739894866943
2,2645,1.024544596672058,0.8474081754684448
3,3527,0.9296350479125977,0.7776253819465637
4,4409,0.8550894260406494,0.713171660900116
5,5291,0.7938690781593323,0.6614746451377869
6,6173,0.74077969789505,0.5939738750457764
7,7055,0.697528064250946,0.5658721327781677
8,7937,0.658428430557251,0.5341746807098389
9,8819,0.6261865496635437,0.5052227973937988
10,9701,0.5975600481033325,0.4676114320755005
11,10583,0.571065366268158,0.45054322481155396
12,11465,0.5483372807502747,0.42687350511550903
13,12347,0.5271317362785339,0.437097430229187
14,13229,0.5082019567489624,0.398123562335968
15,14111,0.4902576208114624,0.3860223591327667
16,14993,0.4727328419685364,0.37258994579315186
17,15875,0.45826080441474915,0.3589242100715637
18,16757,0.44388067722320557,0.3469136953353882
19,17639,0.4302322268486023,0.3301987051963806
20,18521,0.41723838448524475,0.3259012997150421
21,19403,0.4068658947944641,0.3248639702796936
22,20285,0.3963918685913086,0.31007760763168335
23,21167,0.3869679272174835,0.2998141348361969
