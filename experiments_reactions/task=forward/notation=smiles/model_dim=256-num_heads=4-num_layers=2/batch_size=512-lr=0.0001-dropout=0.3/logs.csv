epoch,step,train_loss,val_loss
0,440,1.7899824380874634,1.2690412998199463
1,881,1.265648603439331,1.0425927639007568
2,1322,1.1134119033813477,0.9222118854522705
3,1763,1.0197618007659912,0.8451476097106934
4,2204,0.9502103328704834,0.7726849317550659
5,2645,0.8928395509719849,0.7000086307525635
6,3086,0.8411121368408203,0.6461225748062134
7,3527,0.7959399223327637,0.6035515666007996
8,3968,0.7549744844436646,0.5663179159164429
9,4409,0.7200862765312195,0.5441972017288208
10,4850,0.6904482841491699,0.5200236439704895
11,5291,0.6616250872612,0.49660998582839966
12,5732,0.6373187899589539,0.4864687919616699
13,6173,0.6149183511734009,0.46253272891044617
14,6614,0.5954802632331848,0.44870269298553467
15,7055,0.5772738456726074,0.43488767743110657
16,7496,0.560073971748352,0.4192356467247009
17,7937,0.5457083582878113,0.4050043821334839
18,8378,0.5316969752311707,0.3883998692035675
19,8819,0.5174989104270935,0.3809032440185547
20,9260,0.5045726895332336,0.36940962076187134
21,9701,0.49438560009002686,0.3606964349746704
22,10142,0.484401673078537,0.3556195795536041
23,10583,0.47538521885871887,0.34203895926475525
