epoch,step,train_loss,val_loss
0,881,1.474943995475769,0.9932340979576111
1,1763,1.0019725561141968,0.7993006110191345
2,2645,0.8699584603309631,0.7330470085144043
3,3527,0.7870498299598694,0.6356825232505798
4,4409,0.7170122265815735,0.5569907426834106
5,5291,0.6491177082061768,0.49782320857048035
6,6173,0.586787223815918,0.46778208017349243
7,7055,0.5367128252983093,0.40431055426597595
8,7937,0.4942171573638916,0.38349518179893494
9,8819,0.4613521695137024,0.3563164174556732
10,9701,0.43356531858444214,0.33580145239830017
11,10583,0.4081128239631653,0.3198630213737488
12,11465,0.38673287630081177,0.2854817509651184
13,12347,0.3659970760345459,0.27424144744873047
14,13229,0.3481459319591522,0.2669842839241028
15,14111,0.33112630248069763,0.25383856892585754
16,14993,0.315690279006958,0.23972587287425995
17,15875,0.3024860918521881,0.22920864820480347
18,16757,0.2912697494029999,0.2202901542186737
19,17639,0.27990442514419556,0.21474668383598328
20,18521,0.26945728063583374,0.20235635340213776
21,19403,0.2606320381164551,0.19863452017307281
