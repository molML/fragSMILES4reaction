epoch,step,train_loss,val_loss
0,440,1.93926203250885,1.3604425191879272
1,881,1.3271806240081787,1.1296164989471436
2,1322,1.1623834371566772,1.0084929466247559
3,1763,1.0606040954589844,0.9218122363090515
4,2204,0.9855473041534424,0.8830430507659912
5,2645,0.924236536026001,0.8154619932174683
6,3086,0.8697722554206848,0.7547274827957153
7,3527,0.8203296661376953,0.7013067603111267
8,3968,0.7740598320960999,0.6588104367256165
9,4409,0.7342281937599182,0.6314333081245422
10,4850,0.6992045044898987,0.6109395027160645
11,5291,0.6683735847473145,0.5802283883094788
12,5732,0.6422731876373291,0.5549227595329285
13,6173,0.6187663674354553,0.5476630330085754
14,6614,0.5987459421157837,0.5317364931106567
15,7055,0.5798143148422241,0.5130476355552673
16,7496,0.5629581212997437,0.5077002048492432
17,7937,0.5470077395439148,0.49764305353164673
18,8378,0.5345132946968079,0.4816342890262604
19,8819,0.5197617411613464,0.47206321358680725
20,9260,0.5078630447387695,0.4602222442626953
21,9701,0.497007817029953,0.4576517641544342
22,10142,0.48687776923179626,0.44141528010368347
23,10583,0.4770177900791168,0.4343143403530121
24,11024,0.4673782289028168,0.4197469651699066
