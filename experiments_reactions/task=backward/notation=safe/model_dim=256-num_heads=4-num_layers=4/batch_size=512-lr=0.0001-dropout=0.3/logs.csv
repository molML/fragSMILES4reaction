epoch,step,train_loss,val_loss
0,440,2.199918746948242,1.4883819818496704
1,881,1.4902338981628418,1.2460769414901733
2,1322,1.3087700605392456,1.0995463132858276
3,1763,1.1981197595596313,1.0045256614685059
4,2204,1.1176235675811768,0.9547285437583923
5,2645,1.054710865020752,0.8859942555427551
6,3086,1.0020601749420166,0.8408576846122742
7,3527,0.9586949944496155,0.7944265604019165
8,3968,0.9193252921104431,0.7630577683448792
9,4409,0.884701132774353,0.7266726493835449
10,4850,0.85374516248703,0.7077918648719788
11,5291,0.8247537612915039,0.6744769215583801
12,5732,0.7995773553848267,0.6643503904342651
13,6173,0.7766215801239014,0.6512129306793213
14,6614,0.756136953830719,0.627952516078949
15,7055,0.7371589541435242,0.6039304733276367
16,7496,0.7198171019554138,0.5895557999610901
17,7937,0.7042127251625061,0.5810087323188782
18,8378,0.6904006600379944,0.5676300525665283
19,8819,0.6761398315429688,0.556466817855835
20,9260,0.6631447672843933,0.5488613247871399
21,9701,0.6528735756874084,0.5411466956138611
22,10142,0.6419743299484253,0.5333652496337891
23,10583,0.6319138407707214,0.5213960409164429
24,11024,0.622911810874939,0.5139678716659546
