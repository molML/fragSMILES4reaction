epoch,step,train_loss,val_loss
0,881,1.853934407234192,1.2662276029586792
1,1763,1.2772579193115234,1.049801230430603
2,2645,1.1175566911697388,0.9281893968582153
3,3527,1.0100815296173096,0.8372415900230408
4,4409,0.9295938014984131,0.7791554927825928
5,5291,0.865294873714447,0.7101742625236511
6,6173,0.814067542552948,0.6628106236457825
7,7055,0.7726977467536926,0.6313537955284119
8,7937,0.7358928322792053,0.5943650603294373
9,8819,0.7057600617408752,0.5996884107589722
10,9701,0.678776741027832,0.5547674298286438
11,10583,0.6542372107505798,0.5344263315200806
12,11465,0.6337710022926331,0.5197731852531433
13,12347,0.6144968271255493,0.5313422679901123
14,13229,0.5979149341583252,0.493242084980011
15,14111,0.5820561647415161,0.4780338704586029
16,14993,0.5680390000343323,0.4727023243904114
17,15875,0.5555115938186646,0.4576028883457184
18,16757,0.544547438621521,0.4542405605316162
19,17639,0.5326254367828369,0.4474361538887024
20,18521,0.5226850509643555,0.4340796172618866
21,19403,0.514467716217041,0.4397719204425812
22,20285,0.5058931708335876,0.4198940098285675
