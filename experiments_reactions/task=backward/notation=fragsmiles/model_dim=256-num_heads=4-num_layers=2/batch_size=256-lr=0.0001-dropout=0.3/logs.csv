epoch,step,train_loss,val_loss
0,881,2.7976772785186768,1.785491943359375
1,1763,1.7638881206512451,1.4577668905258179
2,2645,1.5394519567489624,1.278779149055481
3,3527,1.396407961845398,1.1572868824005127
4,4409,1.29643714427948,1.0783342123031616
5,5291,1.222548007965088,1.019876480102539
6,6173,1.1704730987548828,0.9750878214836121
7,7055,1.1270605325698853,0.9337309002876282
8,7937,1.0902279615402222,0.8959447741508484
9,8819,1.0609006881713867,0.8728416562080383
10,9701,1.0362178087234497,0.8498868346214294
11,10583,1.013033151626587,0.8333865404129028
12,11465,0.9943132400512695,0.8176561594009399
13,12347,0.9766388535499573,0.8021993637084961
14,13229,0.9610319137573242,0.7869583964347839
15,14111,0.9454010725021362,0.7760070562362671
16,14993,0.9345366954803467,0.7647711038589478
17,15875,0.9214043617248535,0.7548680305480957
18,16757,0.9123088717460632,0.7459419965744019
19,17639,0.9004167318344116,0.7413559556007385
20,18521,0.8905724287033081,0.7321633696556091
