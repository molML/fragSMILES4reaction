epoch,step,train_loss,val_loss
0,881,2.7505574226379395,1.7681149244308472
1,1763,1.691399097442627,1.3893519639968872
2,2645,1.4366135597229004,1.1739896535873413
3,3527,1.2730178833007812,1.0392696857452393
4,4409,1.1666090488433838,0.9548487663269043
5,5291,1.0885357856750488,0.8959640264511108
6,6173,1.0305516719818115,0.8494634628295898
7,7055,0.983095645904541,0.8080498576164246
8,7937,0.9439830183982849,0.7754378914833069
9,8819,0.9120899438858032,0.76055908203125
10,9701,0.8859633803367615,0.7353256940841675
11,10583,0.8619982600212097,0.716181755065918
12,11465,0.8421239852905273,0.7071055769920349
13,12347,0.8238478302955627,0.6937912106513977
14,13229,0.8072509169578552,0.6807507872581482
15,14111,0.7918339371681213,0.667299211025238
16,14993,0.7799171209335327,0.6589431762695312
17,15875,0.7669313549995422,0.6512526869773865
18,16757,0.7579585313796997,0.6433780193328857
19,17639,0.7461106181144714,0.639110267162323
20,18521,0.737064003944397,0.6321195363998413
