epoch,step,train_loss,val_loss
0,440,2.129742383956909,1.567553997039795
1,881,1.5566085577011108,1.3180090188980103
2,1322,1.3850892782211304,1.194796085357666
3,1763,1.2871041297912598,1.1173523664474487
4,2204,1.2189520597457886,1.054491400718689
5,2645,1.1624411344528198,1.0060086250305176
6,3086,1.1135013103485107,0.9432812333106995
7,3527,1.0663331747055054,0.8898209929466248
8,3968,1.0202094316482544,0.8444506525993347
9,4409,0.9770192503929138,0.8129555583000183
10,4850,0.9383605718612671,0.7813854217529297
11,5291,0.9018393158912659,0.756251871585846
12,5732,0.8694139719009399,0.7439834475517273
13,6173,0.8406989574432373,0.7176697254180908
14,6614,0.8165580630302429,0.6976269483566284
15,7055,0.7956532835960388,0.6882935166358948
16,7496,0.7766057252883911,0.6689293384552002
17,7937,0.7606130242347717,0.6594017148017883
18,8378,0.7477144598960876,0.645649254322052
19,8819,0.7332104444503784,0.6332153677940369
20,9260,0.7209314107894897,0.6317629814147949
21,9701,0.7106757760047913,0.6166744828224182
22,10142,0.7008963227272034,0.6040078997612
23,10583,0.6914668083190918,0.5942832827568054
