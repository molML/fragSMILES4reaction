epoch,step,train_loss,val_loss
0,440,2.126039981842041,1.5578910112380981
1,881,1.536747694015503,1.3104833364486694
2,1322,1.3634244203567505,1.177570104598999
3,1763,1.2567577362060547,1.0924601554870605
4,2204,1.1835752725601196,1.0281281471252441
5,2645,1.1242409944534302,0.9705636501312256
6,3086,1.0744141340255737,0.9145210981369019
7,3527,1.0280979871749878,0.8657220005989075
8,3968,0.9802085757255554,0.8148694634437561
9,4409,0.9321399927139282,0.7816667556762695
10,4850,0.8891611099243164,0.7442560195922852
11,5291,0.8500101566314697,0.7215930223464966
12,5732,0.8185207843780518,0.7033686637878418
13,6173,0.7909213900566101,0.6837297081947327
14,6614,0.7672955989837646,0.6651650667190552
15,7055,0.7459891438484192,0.648859977722168
16,7496,0.725720226764679,0.634304404258728
17,7937,0.7087446451187134,0.6234843134880066
18,8378,0.6949901580810547,0.6087789535522461
19,8819,0.6795521974563599,0.5965503454208374
20,9260,0.6668891310691833,0.588031530380249
21,9701,0.6560783386230469,0.5793502926826477
22,10142,0.6454444527626038,0.5698446035385132
23,10583,0.6352348327636719,0.5586890578269958
24,11024,0.625841498374939,0.5521133542060852
