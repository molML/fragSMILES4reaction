epoch,step,train_loss,val_loss
0,440,1.8986778259277344,1.413234829902649
1,881,1.3766438961029053,1.2167621850967407
2,1322,1.2114219665527344,1.0991681814193726
3,1763,1.101873517036438,1.0011366605758667
4,2204,1.0096193552017212,0.9248063564300537
5,2645,0.9294414520263672,0.8635531663894653
6,3086,0.8626419305801392,0.809698760509491
7,3527,0.8062929511070251,0.7877954840660095
8,3968,0.7609279155731201,0.7694816589355469
9,4409,0.7235512137413025,0.7671629190444946
10,4850,0.6936115026473999,0.7401789426803589
11,5291,0.6663249731063843,0.7346810698509216
12,5732,0.6445475816726685,0.7444196939468384
13,6173,0.6248915195465088,0.7417638301849365
14,6614,0.6076845526695251,0.7092800736427307
15,7055,0.5921192169189453,0.7111527323722839
16,7496,0.5776347517967224,0.7161048650741577
17,7937,0.5645744204521179,0.740631103515625
18,8378,0.5544597506523132,0.7143876552581787
19,8819,0.5428131818771362,0.7516875863075256
20,9260,0.5338096618652344,0.739040195941925
21,9701,0.5250625610351562,0.7604382038116455
